optimizer_config:
    optimizer:
        class_path: torch.optim.AdamW
        init_args:
            lr: 1e-3
            weight_decay: 1e-2
    lr_scheduler:
        scheduler:
            class_path: torch.optim.lr_scheduler.MultiStepLR
            init_args:
                milestones: [800, 1100]
        warmup_config:
            warmup_iters: 500

trainer:
    max_epochs: 1200
